{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ad03035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-02 14:58:28.210966: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5b73e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get preprocessed data:\n",
    "train_file = '../preprocessed_texts.txt'\n",
    "file = open(train_file, \"r\")\n",
    "\n",
    "train_data = file.read()\n",
    "train_data = train_data.split(' ')\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e97aa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocabulary:\n",
    "with open('../vocabulary.pkl', 'rb') as fp:\n",
    "    vocabulary = pickle.load(fp)\n",
    "    \n",
    "vocab_size = len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc355a1a",
   "metadata": {},
   "source": [
    "## Bi-directional LSTM Masked Language Modeling\n",
    "\n",
    "references: \n",
    "\n",
    "https://keras.io/examples/nlp/masked_language_modeling/#create-bert-model-pretraining-model-for-masked-language-modeling\n",
    "\n",
    "https://www.kaggle.com/code/ritvik1909/masked-language-modelling-rnn#Data-Preparation\n",
    "\n",
    "https://keras.io/examples/nlp/bidirectional_lstm_imdb/\n",
    "\n",
    "questions:\n",
    "- should we split data by sentence instead of by fixed window size of 20?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51007c",
   "metadata": {},
   "source": [
    "### more data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "103b3b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert words to vectors\n",
    "vectorized_text = list(map(lambda x: vocabulary[x], train_data))\n",
    "vectorized_text = np.array(vectorized_text)\n",
    "\n",
    "# add [mask] to vocabulary\n",
    "mask_id = vocab_size\n",
    "vocabulary['[mask]'] = mask_id\n",
    "\n",
    "# split data into sequences of length 20\n",
    "vectorized_text_len = len(vectorized_text) - (len(vectorized_text) % 20)\n",
    "vectorized_text = vectorized_text[:vectorized_text_len]\n",
    "vectorized_text = np.reshape(vectorized_text,[-1,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c34a2e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4556,  986, 4556, ..., 1696, 4015,    0],\n",
       "       [ 718, 4250, 3636, ...,    0, 4556, 1095],\n",
       "       [   0, 4556, 4556, ..., 1280, 4556, 4556],\n",
       "       ...,\n",
       "       [1533,  822, 2609, ..., 1954, 1778, 1731],\n",
       "       [1449, 2609,    0, ..., 4556, 2856, 2622],\n",
       "       [4580,    0,  349, ..., 4309, 4556,  165]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f04468a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_one_input_label(sequence):\n",
    "    \n",
    "    # randomly choose one position in sequence to mask\n",
    "    mask = np.random.randint(low=0, high=20)\n",
    "    \n",
    "    # add mask to input\n",
    "    masked_input = [token if i != mask else mask_id for i, token in enumerate(sequence)]\n",
    "    \n",
    "    # set all values in label to -1(ignored by loss function) except the value at the masked position\n",
    "    label = [-1 if i!= mask else token for i, token in enumerate(sequence)]\n",
    "    return masked_input, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76fbd678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get masked inputs and labels\n",
    "def get_masked_inputs_labels(text):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for seq in text:\n",
    "        x,y = mask_one_input_label(seq)\n",
    "        inputs.append(x)\n",
    "        labels.append(y)\n",
    "    inputs = np.array(inputs)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return inputs, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8dcf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = get_masked_inputs_labels(vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4016fd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4556  986 4556  389 4556 3012    0 4556 1965  846 4641 1398 3772 3232\n",
      " 2543 1061    0 1696 5001    0] [  -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1   -1\n",
      "   -1   -1   -1   -1 4015   -1]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[0], labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56a73b",
   "metadata": {},
   "source": [
    "### bi-directional lstm model building and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9830fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define masked language modeling class\n",
    "class LSTM_MLM(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embed_size, input_length):\n",
    "        \"\"\"\n",
    "        The Model class predicts the next words in a sequence.\n",
    "        : param vocab_size : The number of unique words in the data\n",
    "        : param hidden_size   : The size of your desired RNN\n",
    "        : param embed_size : The size of your latent embedding\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.input_length = input_length\n",
    "\n",
    "        ## TODO: define your trainable variables and/or layers here. This should include an\n",
    "        ## embedding component, and any other variables/layers you require.\n",
    "\n",
    "        # embedding layer\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size+1, output_dim=self.embed_size)\n",
    "        self.lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))\n",
    "        self.dense1 = tf.keras.layers.Dense(self.vocab_size, activation='softmax')\n",
    "\n",
    "        # fully connected linear layers\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        You must use an embedding layer as the first layer of your network (i.e. tf.nn.embedding_lookup or tf.keras.layers.Embedding)\n",
    "        :param inputs: word ids of shape (batch_size, 2)\n",
    "        :return: logits: The batch element probabilities as a tensor of shape (batch_size, vocab_size)\n",
    "        \"\"\"\n",
    "\n",
    "        # embedding layer\n",
    "        x = inputs\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = self.lstm(x)\n",
    "        x = self.dense1(x)\n",
    "\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c274c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1104/1104 [==============================] - 272s 241ms/step - loss: 4.9912\n",
      "Epoch 2/20\n",
      "1104/1104 [==============================] - 262s 237ms/step - loss: 4.5843\n",
      "Epoch 3/20\n",
      "1104/1104 [==============================] - 279s 253ms/step - loss: 4.3674\n",
      "Epoch 4/20\n",
      "1104/1104 [==============================] - 430s 389ms/step - loss: 4.1467\n",
      "Epoch 5/20\n",
      "1104/1104 [==============================] - 645s 584ms/step - loss: 3.9180\n",
      "Epoch 6/20\n",
      "1104/1104 [==============================] - 689s 624ms/step - loss: 3.6847\n",
      "Epoch 7/20\n",
      "1104/1104 [==============================] - 778s 705ms/step - loss: 3.4503\n",
      "Epoch 8/20\n",
      "1104/1104 [==============================] - 529s 479ms/step - loss: 3.2179\n",
      "Epoch 9/20\n",
      "1104/1104 [==============================] - 513s 465ms/step - loss: 2.9956\n",
      "Epoch 10/20\n",
      "1104/1104 [==============================] - 512s 464ms/step - loss: 2.7827\n",
      "Epoch 11/20\n",
      "1104/1104 [==============================] - 523s 474ms/step - loss: 2.5808\n",
      "Epoch 12/20\n",
      "1104/1104 [==============================] - 505s 457ms/step - loss: 2.3903\n",
      "Epoch 13/20\n",
      "1104/1104 [==============================] - 560s 507ms/step - loss: 2.2130\n",
      "Epoch 14/20\n",
      "1104/1104 [==============================] - 408s 369ms/step - loss: 2.0471\n",
      "Epoch 15/20\n",
      "1104/1104 [==============================] - 437s 396ms/step - loss: 1.8897\n",
      "Epoch 16/20\n",
      "1104/1104 [==============================] - 256s 232ms/step - loss: 1.7436\n",
      "Epoch 17/20\n",
      "1104/1104 [==============================] - 551s 499ms/step - loss: 1.6072\n",
      "Epoch 18/20\n",
      "1104/1104 [==============================] - 541s 491ms/step - loss: 1.4799\n",
      "Epoch 19/20\n",
      "1104/1104 [==============================] - 304s 275ms/step - loss: 1.3630\n",
      "Epoch 20/20\n",
      "1104/1104 [==============================] - 260s 235ms/step - loss: 1.2535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc7cb52a890>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_MLM(vocab_size, 64, 20)\n",
    "loss_metric = tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1)\n",
    "# accuracy is not a good measure\n",
    "model.compile(loss=loss_metric, optimizer='adam')\n",
    "model.fit(x=inputs, y=labels, batch_size=100, epochs=20) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beb84f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d638eadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5002, 64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cce07961",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"bidirectional_lstm_embedding.csv\", embeddings, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b190b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla, lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bi_lstm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bi_lstm/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"bi_lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35495986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model:\n",
    "bi_lstm_model = tf.keras.models.load_model(\"bi_lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a45f2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 20, 5001), dtype=float32, numpy=\n",
       "array([[[1.08420591e-05, 4.81920279e-06, 2.71167823e-06, ...,\n",
       "         5.65170876e-06, 3.07116788e-05, 1.06291656e-04],\n",
       "        [6.13006979e-09, 1.24815851e-04, 2.29068576e-07, ...,\n",
       "         7.75018416e-05, 7.67877282e-06, 1.62149081e-06],\n",
       "        [1.61006656e-02, 2.63795243e-07, 1.84801465e-07, ...,\n",
       "         3.70968991e-07, 5.22544324e-05, 1.11797908e-05],\n",
       "        ...,\n",
       "        [8.99803638e-07, 2.04359094e-05, 1.09520137e-04, ...,\n",
       "         2.73105870e-05, 1.16686970e-05, 1.19550816e-06],\n",
       "        [2.74908915e-03, 1.22807176e-09, 9.74802097e-05, ...,\n",
       "         1.06047260e-09, 2.86014483e-08, 1.22358079e-08],\n",
       "        [9.74070531e-07, 3.86170897e-04, 1.95058037e-05, ...,\n",
       "         3.52743955e-04, 3.49714799e-04, 5.24173129e-06]]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_lstm_model(inputs[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1242dc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.LSTM_MLM at 0x7fc7e44d5120>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4294ef",
   "metadata": {},
   "source": [
    "### get predicted probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "79ca807a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "\n",
    "def get_predicted_probability(masked_sentence, target_word, model):\n",
    "    masked_sentence = masked_sentence.split(' ')\n",
    "    mask_loc = masked_sentence.index('[mask]')\n",
    "    target_id = vocabulary[target_word]\n",
    "    query_id = [vocabulary[q] for q in masked_sentence]\n",
    "    \n",
    "\n",
    "    query_id = tf.expand_dims(query_id, axis=0)\n",
    "    #print(query_id.shape, query_id)\n",
    "    pred = model(query_id, training=False)[:,mask_loc, target_id]\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd046776",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = '[mask] like beautiful dress'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b1eeb29c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'lstm_mlm_1' (type LSTM_MLM).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (1 total):\n    * <tf.Tensor 'inputs:0' shape=(1, 2) dtype=int32>\n  Keyword arguments: {'training': False}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (1 total):\n    * TensorSpec(shape=(None, 20), dtype=tf.int64, name='inputs')\n  Keyword arguments: {'training': False}\n\nOption 2:\n  Positional arguments (1 total):\n    * TensorSpec(shape=(None, 20), dtype=tf.int64, name='inputs')\n  Keyword arguments: {'training': True}\n\nOption 3:\n  Positional arguments (1 total):\n    * TensorSpec(shape=(None, 20), dtype=tf.int64, name='input_1')\n  Keyword arguments: {'training': False}\n\nOption 4:\n  Positional arguments (1 total):\n    * TensorSpec(shape=(None, 20), dtype=tf.int64, name='input_1')\n  Keyword arguments: {'training': True}\n\nCall arguments received by layer 'lstm_mlm_1' (type LSTM_MLM):\n  • args=('tf.Tensor(shape=(1, 2), dtype=int32)',)\n  • kwargs=<class 'inspect._empty'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_predicted_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_sentence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshe\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbi_lstm_model\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[58], line 12\u001b[0m, in \u001b[0;36mget_predicted_probability\u001b[0;34m(masked_sentence, target_word, model)\u001b[0m\n\u001b[1;32m     10\u001b[0m query_id \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(query_id, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#print(query_id.shape, query_id)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[:,mask_loc, target_id]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred\n",
      "File \u001b[0;32m/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/csci1470/lib/python3.10/site-packages/tensorflow/python/saved_model/function_deserialization.py:295\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m   positional, keyword \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mstructured_input_signature\n\u001b[1;32m    292\u001b[0m   signature_descriptions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    293\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOption \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword arguments: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    294\u001b[0m           index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, _pretty_format_positional(positional), keyword))\n\u001b[0;32m--> 295\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find matching concrete function to call loaded from the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel. Got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_pretty_format_positional(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Expected these arguments to match one of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(saved_function\u001b[38;5;241m.\u001b[39mconcrete_functions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m option(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m))\u001b[38;5;241m.\u001b[39mjoin(signature_descriptions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'lstm_mlm_1' (type LSTM_MLM).\n\nCould not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (1 total):\n    * <tf.Tensor 'inputs:0' shape=(1, 2) dtype=int32>\n  Keyword arguments: {'training': False}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (1 total):\n    * TensorSpec(shape=(None, 20), dtype=tf.int64, name='inputs')\n  Keyword arguments: {'training': False}\n\nOption 2:\n  Positional arguments (1 total):\n    * TensorSpec(shape=(None, 20), dtype=tf.int64, name='inputs')\n  Keyword arguments: {'training': True}\n\nOption 3:\n  Positional arguments (1 total):\n    * TensorSpec(shape=(None, 20), dtype=tf.int64, name='input_1')\n  Keyword arguments: {'training': False}\n\nOption 4:\n  Positional arguments (1 total):\n    * TensorSpec(shape=(None, 20), dtype=tf.int64, name='input_1')\n  Keyword arguments: {'training': True}\n\nCall arguments received by layer 'lstm_mlm_1' (type LSTM_MLM):\n  • args=('tf.Tensor(shape=(1, 2), dtype=int32)',)\n  • kwargs=<class 'inspect._empty'>"
     ]
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence, 'she', bi_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "934b9680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00055029], dtype=float32)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence, 'he', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "305dd1b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00154718], dtype=float32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence, 'queen', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dfe65af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.7876113e-05], dtype=float32)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence, 'king', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "556080d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = 'evil old [mask]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb73c75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.06361172], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence, 'man', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e27cd75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.19437508], dtype=float32)>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence, 'woman', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "469602ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0031174], dtype=float32)>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sentence = 'pretty [mask]'\n",
    "get_predicted_probability(test_sentence, 'girl', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "11a696da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.0016107], dtype=float32)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability(test_sentence, 'boy', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64fc2d",
   "metadata": {},
   "source": [
    "### access embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0ef8cd12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4127, 64)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.layers[0].get_weights()[0]\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed693a",
   "metadata": {},
   "source": [
    "### testing lstm model on HW4 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1f9ab1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('../data/hw4_train.txt', \"r\")\n",
    "\n",
    "hw4_data = file.read()\n",
    "hw4_data = hw4_data.replace('\\n', ' ').split(' ')\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c71b8934",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw4_vocabulary, hw4_vocab_size = get_vocab(hw4_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b88121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert words to vectors\n",
    "hw4_vectorized_text = list(map(lambda x: hw4_vocabulary[x], hw4_data))\n",
    "hw4_vectorized_text = np.array(hw4_vectorized_text)\n",
    "\n",
    "# add [mask] to vocabulary\n",
    "mask_id = vocab_size\n",
    "hw4_vocabulary['[mask]'] = mask_id\n",
    "\n",
    "# split data into sequences of length 20\n",
    "hw4_vectorized_text_len = len(hw4_vectorized_text) - (len(hw4_vectorized_text) % 20)\n",
    "hw4_vectorized_text = hw4_vectorized_text[:hw4_vectorized_text_len]\n",
    "hw4_vectorized_text = np.reshape(hw4_vectorized_text,[-1,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d5989da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hw4_inputs, hw4_labels = get_masked_inputs_labels(hw4_vectorized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0e7a53e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# testing model performance on hw4 data:\n",
    "# model = LSTM_MLM(hw4_vocab_size, 64, 20)\n",
    "# loss_metric = tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1)\n",
    "# model.compile(loss=loss_metric, optimizer='adam')\n",
    "# model.fit(x=hw4_inputs, y=hw4_labels, batch_size=20, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696ff06",
   "metadata": {},
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238aa8ac",
   "metadata": {},
   "source": [
    "references: \"Attention Is All You Need\" paper by Vaswani et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e923d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model):\n",
    "        super(SingleHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.query = tf.keras.layers.Dense(d_model)\n",
    "        self.key = tf.keras.layers.Dense(d_model)\n",
    "        self.value = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, q, k, v, mask):\n",
    "        q = self.query(q)\n",
    "        k = self.key(k)\n",
    "        v = self.value(v)\n",
    "        \n",
    "        dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "        scaled_attention_logits = tf.matmul(q, k, transpose_b=True) / tf.math.sqrt(dk)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "        \n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32f12b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.att = SingleHeadAttention(d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(d_model * 4, activation='relu'),\n",
    "            tf.keras.layers.Dense(d_model)\n",
    "        ])\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.1)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.1)\n",
    "\n",
    "    def call(self, x, training, mask=None):\n",
    "        attn_output, _ = self.att(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f22cb214",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_MLM(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embed_size, input_length):\n",
    "        super().__init__()\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.input_length = input_length\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_dim=self.vocab_size+1, output_dim=self.embed_size)\n",
    "        self.transformer_block = TransformerBlock(self.embed_size)\n",
    "        self.dense1 = tf.keras.layers.Dense(self.vocab_size, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.embedding(x)\n",
    "        x = self.transformer_block(x, training=True)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64138dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "98/98 [==============================] - 6s 37ms/step - loss: 7.6252\n",
      "Epoch 2/20\n",
      "98/98 [==============================] - 4s 37ms/step - loss: 5.9200\n",
      "Epoch 3/20\n",
      "98/98 [==============================] - 4s 37ms/step - loss: 5.3986\n",
      "Epoch 4/20\n",
      "98/98 [==============================] - 4s 36ms/step - loss: 4.7189\n",
      "Epoch 5/20\n",
      "98/98 [==============================] - 4s 37ms/step - loss: 3.8785\n",
      "Epoch 6/20\n",
      "98/98 [==============================] - 4s 37ms/step - loss: 3.0417\n",
      "Epoch 7/20\n",
      "98/98 [==============================] - 4s 38ms/step - loss: 2.2777\n",
      "Epoch 8/20\n",
      "98/98 [==============================] - 3s 34ms/step - loss: 1.6189\n",
      "Epoch 9/20\n",
      "98/98 [==============================] - 4s 38ms/step - loss: 1.1057\n",
      "Epoch 10/20\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 0.7190\n",
      "Epoch 11/20\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 0.4373\n",
      "Epoch 12/20\n",
      "98/98 [==============================] - 4s 41ms/step - loss: 0.2575\n",
      "Epoch 13/20\n",
      "98/98 [==============================] - 4s 42ms/step - loss: 0.1547\n",
      "Epoch 14/20\n",
      "98/98 [==============================] - 4s 40ms/step - loss: 0.1017\n",
      "Epoch 15/20\n",
      "98/98 [==============================] - 4s 42ms/step - loss: 0.0725\n",
      "Epoch 16/20\n",
      "98/98 [==============================] - 4s 45ms/step - loss: 0.0548\n",
      "Epoch 17/20\n",
      "98/98 [==============================] - 4s 43ms/step - loss: 0.0447\n",
      "Epoch 18/20\n",
      "98/98 [==============================] - 5s 47ms/step - loss: 0.0361\n",
      "Epoch 19/20\n",
      "98/98 [==============================] - 4s 43ms/step - loss: 0.0296\n",
      "Epoch 20/20\n",
      "98/98 [==============================] - 4s 39ms/step - loss: 0.0262\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13cf46f50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_t = Transformer_MLM(vocab_size, 64, 20)\n",
    "loss_metric = tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1)\n",
    "model_t.compile(loss=loss_metric, optimizer='adam')\n",
    "model_t.fit(x=inputs, y=labels, batch_size=20, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5bcb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_probability_transformer(masked_sentence, target_word):\n",
    "    masked_sentence = masked_sentence.split(' ')\n",
    "    mask_loc = masked_sentence.index('[mask]')\n",
    "    target_id = vocabulary[target_word]\n",
    "    query_id = [vocabulary[q] for q in masked_sentence]\n",
    "\n",
    "    query_id = tf.expand_dims(query_id, axis=0)\n",
    "    pred = model_t(query_id)[:,mask_loc, target_id]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "050658fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = '[mask] like beauti dress'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f62b708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([2.3778994e-05], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability_transformer(test_sentence, 'she')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fabc4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.00123803], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability_transformer(test_sentence, 'he')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbcd1d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([0.01000271], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability_transformer(test_sentence, 'queen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58a2f92f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([9.1098386e-08], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predicted_probability_transformer(test_sentence, 'king')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
